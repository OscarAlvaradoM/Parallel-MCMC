{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel chido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA, LinearAlgebra, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [3 -2 0; 1 3 -1; 2 1 4]\n",
    "b = [-3, -3, 6]\n",
    "#A\\b = [-1 0 2]\n",
    "\n",
    "M = Diagonal(A) # Tal vez esta es una mejor forma(?)\n",
    "\n",
    "N = M - A\n",
    "\n",
    "T = inv(M) * N\n",
    "\n",
    "f = inv(M) * b\n",
    "\n",
    "nT, mT = size(T)\n",
    "\n",
    "S = zeros(Int64, nT)\n",
    "\n",
    "[S[i] += 1 for i in 1:nT, j in 1:mT if T[i,j] != 0]\n",
    "\n",
    "P = zeros(nT, mT)\n",
    "[P[i,j] = 1/S[i] for i in 1:nT, j in 1:mT if T[i,j] != 0];\n",
    "#0.0  1.0  0.0\n",
    "#0.5  0.0  0.5\n",
    "#0.5  0.5  0.0\n",
    "\n",
    "[P[i,j] = sum(P[i,1:j]) for i = 1:nT, j = 1:mT if P[i,j] != 0];\n",
    "#0.0 1.0 0.0\n",
    "#0.5 0.0 1.0\n",
    "#0.5 1.0 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       "  0.0        0.666667  0.0\n",
       " -0.333333   0.0       0.333333\n",
       " -0.5       -0.25      0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " 0.0  1.0  0.0\n",
       " 0.5  0.0  1.0\n",
       " 0.5  1.0  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 10\n",
    " # Aquí cambiamos la posición del vector solución que queremos aproximar, ya sea X[1], X[2] o X[3]\n",
    "var = 1 \n",
    "\n",
    "u = rand(e)\n",
    "Point = [var]\n",
    "Nextpoint = []\n",
    "#nextpoint = [u[i] for i = 1:40, while u]\n",
    "for tamaño = 1:e\n",
    "    np = 1\n",
    "    while u[tamaño] >= P[Point[tamaño], np]\n",
    "        np += 1\n",
    "    end\n",
    "    push!(Nextpoint, np)\n",
    "    push!(Point, np)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Error: Could not initialize CUDA\n",
      "│   exception = (CuError(CUDA.CUDA_ERROR_UNKNOWN, nothing), Union{Ptr{Nothing}, Base.InterpreterIP}[Ptr{Nothing} @0x00007fe72c88d48e, Ptr{Nothing} @0x00007fe72c8c3f18, Ptr{Nothing} @0x00007fe72c8e303c, Ptr{Nothing} @0x00007fe72c8c24ef, Ptr{Nothing} @0x00007fe72c8c2674, Ptr{Nothing} @0x00007fe72c88ceb1, Ptr{Nothing} @0x00007fe72c88cfb8, Ptr{Nothing} @0x00007fe72c8bb2f9, Ptr{Nothing} @0x00007fe72c8bb5fa, Ptr{Nothing} @0x00007fe72c8bc772, Ptr{Nothing} @0x00007fe72c8c1ddc, Ptr{Nothing} @0x00007fe72c8c1e8c, Ptr{Nothing} @0x00007fe758923082, Ptr{Nothing} @0x00007fe72c88cdad, Ptr{Nothing} @0x00007fe72c8bf6a5, Ptr{Nothing} @0x00007fe72c8bf99a, Ptr{Nothing} @0x00007fe72c8c03fa, Ptr{Nothing} @0x00007fe72c8be290, Ptr{Nothing} @0x00007fe72c8be635, Ptr{Nothing} @0x00007fe758923082, Ptr{Nothing} @0x00007fe72c8bdbdc, Ptr{Nothing} @0x00007fe72c8ba6fd, Ptr{Nothing} @0x00007fe72c8ba713, Ptr{Nothing} @0x00007fe758923082, Ptr{Nothing} @0x00007fe72c8ba675, Ptr{Nothing} @0x00007fe72c8ba6d6, Ptr{Nothing} @0x00007fe758923082, Ptr{Nothing} @0x00007fe75893bba5, Ptr{Nothing} @0x00007fe75893b7ef, Ptr{Nothing} @0x00007fe75893cda3, Ptr{Nothing} @0x00007fe75893dfe7, Base.InterpreterIP in top-level CodeInfo for Main at statement 1, Ptr{Nothing} @0x00007fe75895b329, Ptr{Nothing} @0x00007fe75895bfa4, Ptr{Nothing} @0x00007fe72c89319e, Ptr{Nothing} @0x00007fe75892342a, Ptr{Nothing} @0x00007fe72c891ade, Ptr{Nothing} @0x00007fe75892342a, Ptr{Nothing} @0x00007fe75893260b, Ptr{Nothing} @0x00007fe758932ec1, Ptr{Nothing} @0x00007fe72c84b872, Ptr{Nothing} @0x00007fe72c84ba4e, Ptr{Nothing} @0x00007fe72c84ba6c, Ptr{Nothing} @0x00007fe758923082, Ptr{Nothing} @0x00007fe758941a9e, Ptr{Nothing} @0x0000000000000000])\n",
      "└ @ CUDA /home/oscar/.julia/packages/CUDA/7vLVC/src/initialization.jl:99\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "AssertionError: CUDA.jl did not successfully initialize, and is not usable.",
     "output_type": "error",
     "traceback": [
      "AssertionError: CUDA.jl did not successfully initialize, and is not usable.",
      "",
      "Stacktrace:",
      " [1] libcuda at /home/oscar/.julia/packages/CUDA/7vLVC/src/initialization.jl:50 [inlined]",
      " [2] (::CUDA.var\"#714#cache_fptr!#47\")() at /home/oscar/.julia/packages/CUDA/7vLVC/lib/utils/call.jl:31",
      " [3] macro expansion at /home/oscar/.julia/packages/CUDA/7vLVC/lib/utils/call.jl:39 [inlined]",
      " [4] macro expansion at /home/oscar/.julia/packages/CUDA/7vLVC/lib/cudadrv/libcuda.jl:149 [inlined]",
      " [5] macro expansion at /home/oscar/.julia/packages/CUDA/7vLVC/lib/cudadrv/error.jl:108 [inlined]",
      " [6] cuCtxGetCurrent(::Base.RefValue{Ptr{Nothing}}) at /home/oscar/.julia/packages/CUDA/7vLVC/lib/utils/call.jl:93",
      " [7] CuCurrentContext at /home/oscar/.julia/packages/CUDA/7vLVC/lib/cudadrv/context.jl:81 [inlined]",
      " [8] initialize_thread(::Int64) at /home/oscar/.julia/packages/CUDA/7vLVC/src/state.jl:51",
      " [9] prepare_cuda_call() at /home/oscar/.julia/packages/CUDA/7vLVC/src/state.jl:34",
      " [10] initialize_api() at /home/oscar/.julia/packages/CUDA/7vLVC/lib/cudadrv/error.jl:98",
      " [11] macro expansion at /home/oscar/.julia/packages/CUDA/7vLVC/lib/cudadrv/libcuda.jl:357 [inlined]",
      " [12] macro expansion at /home/oscar/.julia/packages/CUDA/7vLVC/lib/cudadrv/error.jl:108 [inlined]",
      " [13] cuMemAlloc_v2(::Base.RefValue{CuPtr{Nothing}}, ::Int64) at /home/oscar/.julia/packages/CUDA/7vLVC/lib/utils/call.jl:93",
      " [14] alloc at /home/oscar/.julia/packages/CUDA/7vLVC/lib/cudadrv/memory.jl:84 [inlined]",
      " [15] macro expansion at /home/oscar/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]",
      " [16] macro expansion at /home/oscar/.julia/packages/CUDA/7vLVC/src/pool.jl:138 [inlined]",
      " [17] macro expansion at ./util.jl:234 [inlined]",
      " [18] actual_alloc(::Int64) at /home/oscar/.julia/packages/CUDA/7vLVC/src/pool.jl:137",
      " [19] actual_alloc at /home/oscar/.julia/packages/CUDA/7vLVC/src/pool/binned.jl:53 [inlined]",
      " [20] macro expansion at /home/oscar/.julia/packages/CUDA/7vLVC/src/pool/binned.jl:248 [inlined]",
      " [21] macro expansion at /home/oscar/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]",
      " [22] pool_alloc(::Int64, ::Int64) at /home/oscar/.julia/packages/CUDA/7vLVC/src/pool/binned.jl:247",
      " [23] alloc(::Int64) at /home/oscar/.julia/packages/CUDA/7vLVC/src/pool/binned.jl:389",
      " [24] macro expansion at /home/oscar/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]",
      " [25] macro expansion at /home/oscar/.julia/packages/CUDA/7vLVC/src/pool.jl:251 [inlined]",
      " [26] macro expansion at ./util.jl:234 [inlined]",
      " [27] alloc at /home/oscar/.julia/packages/CUDA/7vLVC/src/pool.jl:250 [inlined]",
      " [28] CuArray{Float64,1}(::UndefInitializer, ::Tuple{Int64}) at /home/oscar/.julia/packages/CUDA/7vLVC/src/array.jl:116",
      " [29] CuArray at /home/oscar/.julia/packages/CUDA/7vLVC/src/array.jl:124 [inlined]",
      " [30] CuArray{Float64,N} where N(::UndefInitializer, ::Int64) at /home/oscar/.julia/packages/CUDA/7vLVC/src/array.jl:125",
      " [31] ones(::Type{T} where T, ::Int64) at /home/oscar/.julia/packages/CUDA/7vLVC/src/array.jl:354",
      " [32] top-level scope at In[6]:1"
     ]
    }
   ],
   "source": [
    "d_W = CUDA.ones(Float64, e) # Aquí suponemos W_0 = 1.\n",
    "d_point = CuArray(Point)\n",
    "d_nextpoint = CuArray{Int64}(Nextpoint)\n",
    "d_W_new = CuArray{Float64}(undef, e)\n",
    "d_P = CuArray{Float64}(P)\n",
    "d_T = CuArray{Float64}(T)\n",
    "d_X = CUDA.fill(Float64(f[var]), e)\n",
    "d_f = CuArray(Float64.(f))\n",
    "\n",
    "function kernel(W, W_new, X, T, P, nextpoint, point, f)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    #W_new = W *(T[point, nextpoint]/P[point, nextpoint])\n",
    "    #X[column_T] += W_new * f[nextpoint] # ------------------------Aquí\n",
    "    #W = W_new\n",
    "    #point = nextpoint\n",
    "    W_new[i] = W[i] * CUDA.pow((T[point[i], nextpoint[i]]/P[point[i], nextpoint[i]]), i)\n",
    "    @cushow W_new[i]\n",
    "    if W_new[i] >= 0.05\n",
    "        X[i] +=  W_new[i] * f[nextpoint[i]]\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "@cuda threads = e kernel(d_W, d_W_new, d_X, d_T, d_P, d_nextpoint, d_point, d_f)\n",
    "\n",
    "mean(Array(d_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5127022f0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
